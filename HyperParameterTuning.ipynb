{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is used to show the process of hyper parameter tuning for ridge regression using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is data loading and feature selection, which is the same as in the main.ipynb file. We read data, separate them into three groups according to jet_num and then drop features which are not defined or are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import self-defined modules\n",
    "from implementations import *\n",
    "from tools_xia import *\n",
    "from helpers_xia import *\n",
    "\n",
    "# just to ingore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_tr = 'data/train.csv'\n",
    "yb_tr, data_tr, idx_tr, labels = load_csv_data(data_path_tr, sub_sample=False)\n",
    "\n",
    "# prepare the data using self-defined DataFrame class\n",
    "labels_dataframe = ['Prediction'] + labels\n",
    "data_tr_dataframe = np.concatenate((yb_tr.reshape([-1,1]), data_tr), axis=1)\n",
    "dataframe_tr = DataFrame(data_tr_dataframe, idx_tr.tolist(), labels_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DER_mode_s =119.89\n",
    "DER_mode_b =96.819# 多个值有相同个数，所以于原本不同\n",
    "\n",
    "# replace -999（undefined values of 'DER_mass_MMC'） with mode respectively\n",
    "temp = dataframe_tr.loc(dataframe_tr['DER_mass_MMC']==-999)\n",
    "temp = temp.loc(temp['Prediction']==1)\n",
    "dataframe_tr.loc(temp.index)['DER_mass_MMC'] = DER_mode_s\n",
    "\n",
    "temp = dataframe_tr.loc(dataframe_tr['DER_mass_MMC']==-999)\n",
    "temp = temp.loc(temp['Prediction']==-1)\n",
    "dataframe_tr.loc(temp.index)['DER_mass_MMC'] = DER_mode_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dorp_phi = ['PRI_jet_leading_phi',\n",
    "                    'PRI_jet_subleading_phi',\n",
    "                    'PRI_lep_phi',\n",
    "                    'PRI_met_phi',\n",
    "                    'PRI_tau_phi',]\n",
    "dataframe_tr = dataframe_tr.drop(feature_dorp_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1.   ,  143.905,   81.417, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  -1.   ,  175.864,   16.915, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  -1.   ,  105.594,   50.559, ..., -999.   , -999.   ,    0.   ],\n",
       "       ...,\n",
       "       [  -1.   ,   96.819,   58.179, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  -1.   ,   94.951,   19.362, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  -1.   ,   96.819,   72.756, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_features_by_jet(dataframe):\n",
    "    return {  \n",
    "        0: dataframe.loc( dataframe['PRI_jet_num'] == 0).copy(),\n",
    "        1: dataframe.loc( dataframe['PRI_jet_num'] == 1).copy(),\n",
    "        2: dataframe.loc((dataframe['PRI_jet_num'] == 2) | (dataframe['PRI_jet_num'] == 3)).copy(),\n",
    "    }\n",
    "dataframe_tr_grp = group_features_by_jet(dataframe_tr)\n",
    "dataframe_tr_grp[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DER_deltaeta_jet_jet',\n",
       "  'DER_mass_jet_jet',\n",
       "  'DER_prodeta_jet_jet',\n",
       "  'DER_lep_eta_centrality',\n",
       "  'PRI_jet_leading_pt',\n",
       "  'PRI_jet_leading_eta',\n",
       "  'PRI_jet_subleading_pt',\n",
       "  'PRI_jet_subleading_eta'],\n",
       " ['DER_deltaeta_jet_jet',\n",
       "  'DER_mass_jet_jet',\n",
       "  'DER_prodeta_jet_jet',\n",
       "  'DER_lep_eta_centrality',\n",
       "  'PRI_jet_subleading_pt',\n",
       "  'PRI_jet_subleading_eta'],\n",
       " []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate missing rate \n",
    "def missing_rate(dataframe, miss_number):\n",
    "    features = dataframe.drop(['Prediction'])\n",
    "    missing_rate = []\n",
    "    for feature in features.labels:\n",
    "        data = features.loc(features[feature] ==  miss_number)\n",
    "        if data.values.size != 0:\n",
    "            missing_rate.append(data[feature].size / features[feature].size)\n",
    "        else:\n",
    "            missing_rate.append(0)\n",
    "    missing_rate = np.array(missing_rate).reshape([1, -1]).squeeze()\n",
    "    missing_rate_labels = dataframe.labels[1:]\n",
    "    return DataFrame(missing_rate, [0], missing_rate_labels)\n",
    "\n",
    "# get features with undefined values\n",
    "dataframe_tr_feature_undefined = []\n",
    "for i in range(len(dataframe_tr_grp)):\n",
    "    dataframe_tr_miss = missing_rate(dataframe_tr_grp[i], -999)\n",
    "    dataframe_tr_feature_undefined.append(np.array(dataframe_tr_miss.labels)[dataframe_tr_miss.values == 1].tolist())\n",
    "dataframe_tr_feature_undefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.   , 143.905,  81.417, ...,  86.062,   0.   ,   0.   ],\n",
       "       [ -1.   , 175.864,  16.915, ...,  53.131,   0.   ,   0.   ],\n",
       "       [ -1.   , 105.594,  50.559, ..., 129.804,   0.   ,   0.   ],\n",
       "       ...,\n",
       "       [ -1.   ,  96.819,  58.179, ...,  80.408,   0.   ,   0.   ],\n",
       "       [ -1.   ,  94.951,  19.362, ..., 112.718,   0.   ,   0.   ],\n",
       "       [ -1.   ,  96.819,  72.756, ...,  99.405,   0.   ,   0.   ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop features with undefined values in each group\n",
    "dataframe_tr_grp[0] = dataframe_tr_grp[0].drop(dataframe_tr_feature_undefined[0])\n",
    "dataframe_tr_grp[1] = dataframe_tr_grp[1].drop(dataframe_tr_feature_undefined[1])\n",
    "# group2 have no feature with undefined values\n",
    "dataframe_tr_grp[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PRI_jet_num', 'PRI_jet_all_pt'], [], []]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_tr_feature_zero = []\n",
    "for i in range(len(dataframe_tr_grp)):\n",
    "    dataframe_tr_miss = missing_rate(dataframe_tr_grp[i], 0)\n",
    "    dataframe_tr_feature_zero.append(np.array(dataframe_tr_miss.labels)[dataframe_tr_miss.values == 1].tolist())\n",
    "dataframe_tr_feature_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.   , 143.905,  81.417, ...,  -0.522,  31.082,  86.062],\n",
       "       [ -1.   , 175.864,  16.915, ...,   0.798,   2.723,  53.131],\n",
       "       [ -1.   , 105.594,  50.559, ...,   0.21 ,  37.791, 129.804],\n",
       "       ...,\n",
       "       [ -1.   ,  96.819,  58.179, ...,   0.308,  46.737,  80.408],\n",
       "       [ -1.   ,  94.951,  19.362, ...,  -0.874,  12.15 , 112.718],\n",
       "       [ -1.   ,  96.819,  72.756, ...,   1.49 ,  40.729,  99.405]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop features with undefined values in each group\n",
    "# Because only the first group has all zeros column, here we only \n",
    "dataframe_tr_grp[0] = dataframe_tr_grp[0].drop(dataframe_tr_feature_zero[0])\n",
    "dataframe_tr_grp[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature 'PRI_jet_num' which is already used for grouping\n",
    "dataframe_tr_grp[1] = dataframe_tr_grp[1].drop('PRI_jet_num')\n",
    "dataframe_tr_grp[2] = dataframe_tr_grp[2].drop('PRI_jet_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dorp_corr0 = list(['DER_mass_MMC','DER_pt_tot','PRI_tau_pt','PRI_lep_pt'])\n",
    "feature_dorp_corr1 = list(['DER_mass_MMC','DER_pt_h', 'DER_sum_pt', 'PRI_met_sumet','PRI_jet_all_pt','PRI_lep_pt'])\n",
    "feature_dorp_corr2 = list(['DER_mass_MMC','DER_pt_h', 'DER_sum_pt', 'PRI_met_sumet','PRI_jet_all_pt','PRI_lep_pt'])\n",
    "\n",
    "dataframe_tr_grp[0] = dataframe_tr_grp[0].drop(feature_dorp_corr0)\n",
    "dataframe_tr_grp[1] = dataframe_tr_grp[1].drop(feature_dorp_corr1)\n",
    "dataframe_tr_grp[2] = dataframe_tr_grp[2].drop(feature_dorp_corr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Grid Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading data and selecting features, now we can start hyper parameter tuning. Here we define functions `grid_serach` and `ridge_grid_search` to implement grid search and function `get_best_parameters` to return best parameters based on test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(para1,para2, acc):\n",
    "    \"\"\"\n",
    "    Get the best degree and lambda from the result of grid search.\n",
    "    \n",
    "    Inputs:\n",
    "        para1,para2:\n",
    "        Range of parameters in numpy.array.\n",
    "        \n",
    "        acc:\n",
    "        Accuracy matrix saving the accuracy of each \n",
    "    \n",
    "    \"\"\"\n",
    "    max_row, max_col = np.unravel_index(np.argmax(acc), acc.shape)\n",
    "    return acc[max_row, max_col], para1[max_row], para2[max_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(y, tx, para1, para2):\n",
    "    \"\"\"\n",
    "    Function implements grid search.\n",
    "    \n",
    "    Inputs:\n",
    "        y,tx:\n",
    "        Label and data for model training.\n",
    "        \n",
    "        para1,para2:\n",
    "        Range of parameters in numpy.array.\n",
    "    \n",
    "    Result:\n",
    "        acc_tr,acc_te:\n",
    "        Average accuracy of 10-fold cross validation for training set and test set.\n",
    "    \"\"\"\n",
    "    acc_tr = np.zeros((len(para1), len(para2)))\n",
    "    acc_te = np.zeros((len(para1), len(para2)))\n",
    "    tx = log_process(tx)\n",
    "    # k_indices = build_k_indices(y, k_fold=3, seed=1)\n",
    "    for i in range(0,len(para1)):\n",
    "        for j in range(0,len(para2)):\n",
    "            tx,_,_ = standardize(tx)\n",
    "            tx_poly = build_poly(tx, para1[i])\n",
    "            # tx_poly,_,_ = standardize(tx_poly)\n",
    "            lambda_ = para2[j]\n",
    "            #_,acc_tr[i][j],acc_te[i][j] = cross_validation(y, tx_poly, k_indices, k=0, regression_method=ridge_regression, lambda_=lambda_)\n",
    "            _,acc_tr[i][j],acc_te[i][j] = cv_loop(y=y, x=tx_poly, k_fold=3, seed=10, regression_method=ridge_regression, lambda_=lambda_)\n",
    "    return acc_tr,acc_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_grid_search(degrees,lambdas):\n",
    "    \"\"\"\n",
    "    The function is used for hyper parameter tuning for ridge regression using grid search.\n",
    "    \n",
    "    Inputs:\n",
    "        degrees: \n",
    "        Numpy.array. Degrees range for grid search.\n",
    "        \n",
    "        lambdas: \n",
    "        Numpy.array. Lambdas range for grid search.\n",
    "        \n",
    "    Return:\n",
    "        The average accuracy of 10-fold cross validation of training set and test set.\n",
    "    \"\"\"\n",
    "    acc_tr = []\n",
    "    acc_te = []\n",
    "    for i in range(len(dataframe_tr_grp)):\n",
    "        tx = dataframe_tr_grp[i].drop('Prediction').values\n",
    "        # tx = feature_tr_grp[i].drop(columns = ['Id','Prediction']).values\n",
    "        y = (dataframe_tr_grp[i])['Prediction']\n",
    "        # y = feature_tr_grp[i].Prediction.replace(['s','b'],[1,-1]).values\n",
    "        acc_tr_tmp,acc_te_tmp = grid_search(y,tx,degrees,lambdas)\n",
    "        acc_tr.append(acc_tr_tmp)\n",
    "        acc_te.append(acc_te_tmp)\n",
    "    return acc_tr,acc_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the degrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degrees = np.arange(11)+1\n",
    "degrees = [1,5,9,11,13,15]\n",
    "lambdas = [0.001,0.01,0.1]\n",
    "acc_tr,acc_te = ridge_grid_search(degrees,lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridsearch(acc_tr,acc_te,degrees,lambdas):\n",
    "    \"\"\"\n",
    "    This function is used to plot the result of grid search on accuracy over different values of hyper parameters.\n",
    "    \n",
    "    Inputs:\n",
    "        acc_tr,acc_te: \n",
    "        The average accuracy of 10-fold cross validation of training set and test set.\n",
    "        \n",
    "        degrees,lambdas:\n",
    "        Numpy.array. Degrees and lambdas range for grid search.\n",
    "    \"\"\"\n",
    "    fig,ax = plt.subplots(3,3,figsize = (30,30))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for j in range(len(acc_tr)):\n",
    "        for i in range(acc_tr[0].shape[1]):\n",
    "            ax[3*j+i].plot(degrees, acc_tr[j][:,i], color='r', marker='s', label=\"Train Accuray\" )\n",
    "            ax[3*j+i].plot(degrees, acc_te[j][:,i], color='b', marker='v', label=\"Test Accuracy\" )\n",
    "            ax[3*j+i].plot(degrees, (acc_te[j][:,i]+acc_tr[j][:,i])/2, color='g', marker='^', label=\"Average Accuracy\" )\n",
    "            ax[3*j+i].set_title('Lambda = '+str(lambdas[i]))\n",
    "            ax[3*j+i].set_xlabel('Degree',size=15)\n",
    "            ax[3*j+i].set_ylabel('Accuracy',size=15)\n",
    "            ax[3*j+i].legend()\n",
    "        acc,degree,lambda_ = get_best_parameters(degrees,lambdas, acc_te[j])\n",
    "        print(\"For group jet_num = {j}, best test accuracy={acc}, poly degree={degree}, lambda={lambda_}\".format(j = j,acc=acc, degree=degree, lambda_ = lambda_))\n",
    "    fig.suptitle('Grid Search Result over Polynomial Degree and Lambda',size=30,y=0.93)\n",
    "    fig.text(0.5, 0.9, 'Group jet_num = 0', ha='center', va='center',size = 25)\n",
    "    fig.text(0.5, 0.63, 'Group jet_num = 1', ha='center', va='center',size = 25)\n",
    "    fig.text(0.5, 0.35, 'Group jet_num = 2,3', ha='center', va='center',size = 25)\n",
    "    fig.subplots_adjust(hspace=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch(acc_tr,acc_te,degrees,lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
