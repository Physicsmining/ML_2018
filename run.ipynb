{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data...Completed\n"
     ]
    }
   ],
   "source": [
    "# import basic packages\n",
    "import numpy as np\n",
    "# import self-defined modules\n",
    "from implementations import *\n",
    "from tools import *\n",
    "from helpers import *\n",
    "# just to ingore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------- load train and test data -------------------- #\n",
    "print('Start loading data...',end='')\n",
    "data_path_tr = 'data/train.csv'\n",
    "data_path_te = 'data/test.csv'\n",
    "yb_tr, data_tr, idx_tr, labels = load_csv_data(data_path_tr, sub_sample=False)\n",
    "yb_te, data_te, idx_te, _      = load_csv_data(data_path_te, sub_sample=False)\n",
    "\n",
    "# prepare the data using self-defined DataFrame class\n",
    "labels_dataframe = ['Prediction'] + labels\n",
    "data_tr_dataframe = np.concatenate((yb_tr.reshape([-1, 1]), data_tr), axis=1)\n",
    "data_te_dataframe = np.concatenate((yb_te.reshape([-1, 1]), data_te), axis=1)\n",
    "dataframe_tr = DataFrame(data_tr_dataframe, idx_tr.tolist(), labels_dataframe)\n",
    "dataframe_te = DataFrame(data_te_dataframe, idx_te.tolist(), labels_dataframe)\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing data...Completed\n"
     ]
    }
   ],
   "source": [
    "# -------------------- data processing -------------------- #\n",
    "# replace missing values with mode\n",
    "print('Start processing data...',end='')\n",
    "DER_mode_s_tr = 119.89\n",
    "DER_mode_b_tr = 96.819\n",
    "temp = dataframe_tr.loc(dataframe_tr['DER_mass_MMC']==-999)\n",
    "temp = temp.loc(temp['Prediction']==1)\n",
    "dataframe_tr.loc(temp.index)['DER_mass_MMC'] = DER_mode_s_tr\n",
    "temp = dataframe_tr.loc(dataframe_tr['DER_mass_MMC']==-999)\n",
    "temp = temp.loc(temp['Prediction']==-1)\n",
    "dataframe_tr.loc(temp.index)['DER_mass_MMC'] = DER_mode_b_tr\n",
    "\n",
    "DER_mode_te = 96.728\n",
    "temp = dataframe_te.loc(dataframe_te['DER_mass_MMC']==-999)\n",
    "dataframe_te.loc(temp.index)['DER_mass_MMC'] = DER_mode_te\n",
    "\n",
    "# drop features\n",
    "feature_dorp_phi = ['PRI_jet_leading_phi', \n",
    "                    'PRI_jet_subleading_phi', \n",
    "                    'PRI_lep_phi', \n",
    "                    'PRI_met_phi', \n",
    "                    'PRI_tau_phi']\n",
    "dataframe_tr = dataframe_tr.drop(feature_dorp_phi)\n",
    "dataframe_te = dataframe_te.drop(feature_dorp_phi)\n",
    "# divide training data to 3 groups according to feature 'PRI_jet_num'\n",
    "def group_features_by_jet(dataframe):\n",
    "    return {  \n",
    "        0: dataframe.loc( dataframe['PRI_jet_num'] == 0).copy(),\n",
    "        1: dataframe.loc( dataframe['PRI_jet_num'] == 1).copy(),\n",
    "        2: dataframe.loc((dataframe['PRI_jet_num'] == 2) | (dataframe['PRI_jet_num'] == 3)).copy()}\n",
    "dataframe_tr_grp = group_features_by_jet(dataframe_tr)\n",
    "dataframe_te_grp = group_features_by_jet(dataframe_te)\n",
    "# drop features with undefined values (features whose missing rate of -999 are 100%)\n",
    "feature_undefined_gp0 = ['DER_deltaeta_jet_jet',\n",
    "                         'DER_mass_jet_jet',\n",
    "                         'DER_prodeta_jet_jet',\n",
    "                         'DER_lep_eta_centrality',\n",
    "                         'PRI_jet_leading_pt',\n",
    "                         'PRI_jet_leading_eta',\n",
    "                         'PRI_jet_subleading_pt',\n",
    "                         'PRI_jet_subleading_eta']\n",
    "feature_undefined_gp1 = ['DER_deltaeta_jet_jet',\n",
    "                         'DER_mass_jet_jet',\n",
    "                         'DER_prodeta_jet_jet',\n",
    "                         'DER_lep_eta_centrality',\n",
    "                         'PRI_jet_subleading_pt',\n",
    "                         'PRI_jet_subleading_eta']\n",
    "dataframe_tr_grp[0] = dataframe_tr_grp[0].drop(feature_undefined_gp0)\n",
    "dataframe_tr_grp[1] = dataframe_tr_grp[1].drop(feature_undefined_gp1)\n",
    "dataframe_te_grp[0] = dataframe_te_grp[0].drop(feature_undefined_gp0)\n",
    "dataframe_te_grp[1] = dataframe_te_grp[1].drop(feature_undefined_gp1)\n",
    "# drop feature 'PRI_jet_num' which is already used for grouping\n",
    "dataframe_tr_grp[0] = dataframe_tr_grp[0].drop('PRI_jet_num')\n",
    "dataframe_tr_grp[1] = dataframe_tr_grp[1].drop('PRI_jet_num')\n",
    "dataframe_tr_grp[2] = dataframe_tr_grp[2].drop('PRI_jet_num')\n",
    "dataframe_te_grp[0] = dataframe_te_grp[0].drop('PRI_jet_num')\n",
    "dataframe_te_grp[1] = dataframe_te_grp[1].drop('PRI_jet_num')\n",
    "dataframe_te_grp[2] = dataframe_te_grp[2].drop('PRI_jet_num')\n",
    "# drop features with 0 values \n",
    "dataframe_tr_grp[0] = dataframe_tr_grp[0].drop('PRI_jet_all_pt')\n",
    "dataframe_te_grp[0] = dataframe_te_grp[0].drop('PRI_jet_all_pt')\n",
    "# get the finally data\n",
    "data_tr_grp = []     \n",
    "pred_tr_grp = []     \n",
    "for index in range(len(dataframe_tr_grp)):\n",
    "    data_tr_grp.append(dataframe_tr_grp[index].drop('Prediction').values)\n",
    "    pred_tr_grp.append((dataframe_tr_grp[index])['Prediction'])\n",
    "data_te_grp = []     \n",
    "pred_te_grp = []     \n",
    "for index in range(len(dataframe_te_grp)):\n",
    "    data_te_grp.append(dataframe_te_grp[index].drop('Prediction').values)\n",
    "    pred_te_grp.append((dataframe_te_grp[index])['Prediction'])    \n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...Completed\n"
     ]
    }
   ],
   "source": [
    "# -------------------- model training -------------------- #\n",
    "# use ridge regression model\n",
    "print('Start training...', end='')    \n",
    "lambda_ = 0.001\n",
    "degrees = [11,10,11]\n",
    "k_fold = 10\n",
    "seed = 10\n",
    "y_te = []\n",
    "w = []\n",
    "for i in range(len(data_tr_grp)):\n",
    "    # model training\n",
    "    x = data_tr_grp[i]\n",
    "    x = log_process(x)\n",
    "    x, _ ,_ = standardize(x)\n",
    "    x_tr = build_poly(x,degrees[i])\n",
    "    y_tr = pred_tr_grp[i]\n",
    "    w_tmp, _, _ = cv_loop(y_tr, x_tr, k_fold , seed, ridge_regression, lambda_=lambda_)\n",
    "    w.append(w_tmp)\n",
    "    # test model\n",
    "    x = data_te_grp[i]\n",
    "    x = log_process(x)\n",
    "    x, _, _ = standardize(x)\n",
    "    x_te = build_poly(x, degrees[i])\n",
    "    y_te.append(predict_labels(w[i], x_te))\n",
    "    \n",
    "y_pred_te = np.concatenate((y_te[0],y_te[1],y_te[2]))\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating prediction files...Completed\n"
     ]
    }
   ],
   "source": [
    "# -------------------- generate prediction files -------------------- #\n",
    "print('Start generating prediction files...', end='')\n",
    "output_path = 'data/output_ridge_regression_final.csv'\n",
    "create_csv_submission(idx_te, y_pred_te, output_path)\n",
    "print('Completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
